{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T00:33:34.479567Z",
     "start_time": "2025-03-24T00:33:31.267022Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "# nltk.download(\"stopwords\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Steven\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:33:34.513455Z",
     "start_time": "2025-03-24T00:33:34.479567Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "d48825add4d534a5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:34:05.862664Z",
     "start_time": "2025-03-24T00:33:34.513455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = './data/'\n",
    "# data_path = 'G:/GaTech Dropbox/Nian Liu/CSE6250_BDH/Project/Heart-failure-prediction/data/'\n",
    "df_data = pd.read_csv(data_path + 'data_processed.csv')\n",
    "df_data['TOKENS'] = df_data['CLEAN_TEXT'].apply(nltk.word_tokenize)\n",
    "\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# def remove_stopwords_nltk(list_tokens):\n",
    "#     return [token for token in list_tokens if token.lower() not in stop_words]\n",
    "# df_data['TOKENS'] = df_data['TOKENS'].apply(remove_stopwords_nltk)\n",
    "\n",
    "df_data_genRe = df_data[['TOKENS', 'GEN_RE']]\n",
    "df_data_30Re = df_data[['TOKENS', '30_RE']]"
   ],
   "id": "4a6c31f18c153996",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Download word2vec file from Kaggle: https://www.kaggle.com/datasets/alexiscorona/pubmed-and-pmc-w2v/",
   "id": "c4f4811780d3548"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:34:24.499602Z",
     "start_time": "2025-03-24T00:34:05.862664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(\"PubMed-and-PMC-w2v.bin\", binary=True)\n",
    "# w2v = KeyedVectors.load_word2vec_format(\"PubMed-w2v.bin\", binary=True)"
   ],
   "id": "93748ded704bace2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:34:24.503332Z",
     "start_time": "2025-03-24T00:34:24.499602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pos_genRe_idx = np.where((df_data['GEN_RE'] == 1))[0]\n",
    "neg_genRe_idx = np.where((df_data['GEN_RE'] == 0))[0]\n",
    "pos_30Re_idx = np.where((df_data['30_RE'] == 1))[0]\n",
    "neg_30Re_idx = np.where((df_data['30_RE'] == 0))[0]"
   ],
   "id": "6923af537764554a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:34:24.537008Z",
     "start_time": "2025-03-24T00:34:24.503332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vectorize(tokens):\n",
    "    vectors = [w2v[token] if token in w2v else np.random.uniform(-1, 1, (200,)).astype(np.float32) for token in tokens]\n",
    "    return np.array(vectors)\n",
    "\n",
    "def generate_dataset(df_data, pos_idx, neg_idx, re_type):\n",
    "    num_pos = len(pos_idx)\n",
    "    # labels = [1] * num_pos + [0] * num_pos\n",
    "    neg_idx_sample = np.random.choice(neg_idx, size=num_pos, replace=False)\n",
    "    all_idx = pos_idx.tolist() + neg_idx_sample.tolist()\n",
    "    tokens_all = df_data.iloc[all_idx, :]['TOKENS'].to_list()\n",
    "    labels = df_data.iloc[all_idx][re_type].to_list()\n",
    "    vectors_all = [vectorize(tokens) for tokens in tokens_all]\n",
    "    if re_type == '30_RE':\n",
    "        return vectors_all, labels, neg_idx_sample\n",
    "    return vectors_all, labels\n",
    "\n",
    "def generate_dataset_oversample(df_data, pos_idx, neg_idx, re_type):\n",
    "    num_neg = len(neg_idx)\n",
    "    # labels = [1] * num_pos + [0] * num_pos\n",
    "    pos_idx_sample = np.random.choice(pos_idx, size=num_neg, replace=True)\n",
    "    all_idx = neg_idx.tolist() + pos_idx_sample.tolist()\n",
    "    tokens_all = df_data.iloc[all_idx, :]['TOKENS'].to_list()\n",
    "    labels = df_data.iloc[all_idx][re_type].to_list()\n",
    "    vectors_all = [vectorize(tokens) for tokens in tokens_all]\n",
    "    return vectors_all, labels\n",
    "\n",
    "def collate_data(batch):\n",
    "    batch = sorted(batch, key=lambda x: x[0].shape[0])[::-1]\n",
    "    max_len = batch[0][0].shape[0]\n",
    "    labels = [i[1] for i in batch]\n",
    "    \n",
    "    vectors = []\n",
    "    for itm in batch:\n",
    "        if itm[0].shape[0] < max_len:\n",
    "            vectors.append(np.pad(itm[0], ((0, max_len - itm[0].shape[0]), (0, 0)), mode='constant', constant_values=0))\n",
    "        else:\n",
    "            vectors.append(itm[0])\n",
    "    vectors = np.stack(vectors, axis=0)\n",
    "    return torch.tensor(vectors, dtype=torch.float), torch.tensor(labels, dtype=torch.float)"
   ],
   "id": "e81f557dc48ea655",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:34:24.542068Z",
     "start_time": "2025-03-24T00:34:24.537008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HFDataset(Dataset):\n",
    "    def __init__(self, vectors_all, labels):\n",
    "        self.vectors_all = vectors_all\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        vectors = self.vectors_all[index]\n",
    "        return vectors, self.labels[index]"
   ],
   "id": "3d8282ce5f55ca24",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:34:24.548579Z",
     "start_time": "2025-03-24T00:34:24.542068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HFCNN(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super(HFCNN, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(1, 200))\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(2, 200))\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(3, 200))\n",
    "        # self.conv4 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(4, 200))\n",
    "        # self.conv5 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(5, 200))\n",
    "        # self.conv6 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(6, 200))\n",
    "        # self.conv7 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(7, 200))\n",
    "        # self.conv8 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(8, 200))\n",
    "        # self.conv9 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(9, 200))\n",
    "        # self.conv10 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(10, 200))\n",
    "        # self.conv11 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(11, 200))\n",
    "        # self.conv12 = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(12, 200))\n",
    "        \n",
    "        # self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        # self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        # self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.dp = nn.Dropout(0.5) # default is 0.5, 0.4 is worse, 0.6 gets lower val loss but acc seems to be similar\n",
    "        self.FC1 = nn.Linear(in_features=out_channels * 3, out_features=1)\n",
    "        # self.FC2 = nn.Linear(in_features=16, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "                \n",
    "        feature1 = F.relu(self.conv1(x).squeeze(3))\n",
    "        feature2 = F.relu(self.conv2(x).squeeze(3))\n",
    "        feature3 = F.relu(self.conv3(x).squeeze(3))\n",
    "        # feature4 = F.relu(self.conv4(x).squeeze(3))\n",
    "        # feature5 = F.relu(self.conv5(x).squeeze(3))\n",
    "        # feature6 = F.relu(self.conv6(x).squeeze(3))\n",
    "        # feature7 = F.relu(self.conv7(x).squeeze(3))\n",
    "        # feature8 = F.relu(self.conv8(x).squeeze(3))\n",
    "        # feature9 = F.relu(self.conv9(x).squeeze(3))\n",
    "        # feature10 = F.relu(self.conv10(x).squeeze(3))\n",
    "        # feature11 = F.relu(self.conv11(x).squeeze(3))\n",
    "        # feature12 = F.relu(self.conv12(x).squeeze(3))\n",
    "                \n",
    "        feature1 = F.max_pool1d(feature1, feature1.size(2)).squeeze(2)\n",
    "        feature2 = F.max_pool1d(feature2, feature2.size(2)).squeeze(2)\n",
    "        feature3 = F.max_pool1d(feature3, feature3.size(2)).squeeze(2)\n",
    "        # feature4 = F.max_pool1d(feature4, feature4.size(2)).squeeze(2)\n",
    "        # feature5 = F.max_pool1d(feature5, feature5.size(2)).squeeze(2)\n",
    "        # feature6 = F.max_pool1d(feature6, feature6.size(2)).squeeze(2)\n",
    "        # feature7 = F.max_pool1d(feature7, feature7.size(2)).squeeze(2)\n",
    "        # feature8 = F.max_pool1d(feature8, feature8.size(2)).squeeze(2)\n",
    "        # feature9 = F.max_pool1d(feature9, feature9.size(2)).squeeze(2)\n",
    "        # feature10 = F.max_pool1d(feature10, feature10.size(2)).squeeze(2)\n",
    "        # feature11 = F.max_pool1d(feature11, feature11.size(2)).squeeze(2)\n",
    "        # feature12 = F.max_pool1d(feature12, feature12.size(2)).squeeze(2)\n",
    "\n",
    "        # feature1 = self.bn1(feature1)\n",
    "        # feature2 = self.bn2(feature2)\n",
    "        # feature3 = self.bn3(feature3)\n",
    "        \n",
    "        features = torch.cat((feature1, feature2, feature3), dim=1) #, feature4, feature5, feature6, feature7, feature8, feature9, feature10, feature11, feature12), dim=1)\n",
    "        output = F.relu(features)\n",
    "        output = self.FC1(output).squeeze(1)\n",
    "\n",
    "        # output = self.dp(output)\n",
    "        # output = self.FC2(output).squeeze(1)\n",
    "        \n",
    "        return output    "
   ],
   "id": "5beac4bf949389c7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## General readmission case",
   "id": "e405ac3a47e27cad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T14:52:25.397205Z",
     "start_time": "2025-03-22T14:51:47.569096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectors_all_genRe, labels_genRe = generate_dataset_oversample(df_data_genRe, pos_genRe_idx, neg_genRe_idx, 'GEN_RE')\n",
    "x_train, x_test, y_train, y_test = train_test_split(vectors_all_genRe, labels_genRe, test_size=0.1, shuffle=True)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, shuffle=True)\n",
    "dataset_train = HFDataset(x_train, y_train)\n",
    "dataset_val = HFDataset(x_val, y_val)\n",
    "dataset_test = HFDataset(x_test, y_test)"
   ],
   "id": "be73b49e2012acf7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T14:52:40.249458Z",
     "start_time": "2025-03-22T14:52:40.243342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(dataset=dataset_train, batch_size=128, shuffle=True, collate_fn=collate_data) # 128 is good and the default, decreasing batch size actually hurts performance (16 did not work, did not test others)\n",
    "val_loader = DataLoader(dataset=dataset_val, batch_size=128, shuffle=True, collate_fn=collate_data)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=128, shuffle=True, collate_fn=collate_data)"
   ],
   "id": "a1d454270e8deb60",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T04:00:36.946885Z",
     "start_time": "2025-03-22T03:00:46.691918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HFCNN(1024).to(device) # 1024 best so far, performance increases monotonically \n",
    "num_epoch = 50\n",
    "sizes = {'training': len(x_train), 'validation': len(x_val)}\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0075) # 0.01 is the default, 0.0075 is the best so far, 0.02 is already too high and 0.005 is too low\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_val_loss = np.inf\n",
    "# best_val_acc = 0.\n",
    "train_loss_ls = []\n",
    "val_loss_ls = []\n",
    "train_acc_ls = []\n",
    "val_acc_ls = []\n",
    "for epoch in range(num_epoch):\n",
    "    print('Epoch {} of {}'.format(epoch+1, num_epoch))\n",
    "    print('-' * 20)\n",
    "    for phase in ['training', 'validation']:\n",
    "        if phase == 'training':\n",
    "            model.train()\n",
    "            dataloader = train_loader\n",
    "        else:\n",
    "            model.eval()\n",
    "            dataloader = val_loader\n",
    "        epoch_loss = 0.\n",
    "        epoch_correct = 0.\n",
    "        for i, (input, target) in enumerate(dataloader):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase == 'training'):\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target)\n",
    "                if phase == 'training':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            epoch_loss += loss.item() * input.shape[0]\n",
    "            preds = (F.sigmoid(output) > 0.5).float()\n",
    "            epoch_correct += torch.sum(preds == target.data)\n",
    "\n",
    "        epoch_loss = epoch_loss / sizes[phase]\n",
    "        epoch_acc = (epoch_correct / sizes[phase]).item()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            train_loss_ls.append(epoch_loss)\n",
    "            train_acc_ls.append(epoch_acc)\n",
    "        else:\n",
    "            val_loss_ls.append(epoch_loss)\n",
    "            val_acc_ls.append(epoch_acc)\n",
    "        \n",
    "        # if phase == 'validation' and epoch_acc > best_val_acc:\n",
    "        #     best_val_acc = epoch_acc\n",
    "        #     torch.save(model.state_dict(), 'best_CNN_model.pth')\n",
    "        \n",
    "        print('{} phase, current loss is {}'.format(phase, epoch_loss))\n",
    "        print('{} phase, current accuracy is {}'.format(phase, epoch_acc))\n",
    "        print()\n",
    "        \n",
    "        if phase == 'validation' and epoch_loss < best_val_loss:\n",
    "            best_val_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), 'best_CNN_model.pth')\n",
    "            print('Best model saved')\n",
    "            print()\n",
    "\n",
    "training_curves = {'train loss': train_loss_ls, 'train accuracy': train_acc_ls, 'val loss': val_loss_ls, 'val accuracy': val_acc_ls}\n",
    "training_curves = pd.DataFrame(training_curves)\n",
    "training_curves.to_csv('training_curves.csv', index=False)"
   ],
   "id": "42257c3133a0ff80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.6720027145491309\n",
      "training phase, current accuracy is 0.5901699066162109\n",
      "\n",
      "validation phase, current loss is 0.6361292267909376\n",
      "validation phase, current accuracy is 0.5897714495658875\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 2 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.6084549724280953\n",
      "training phase, current accuracy is 0.6584244966506958\n",
      "\n",
      "validation phase, current loss is 0.6079904202927183\n",
      "validation phase, current accuracy is 0.638193666934967\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 3 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.593874150305963\n",
      "training phase, current accuracy is 0.6731153130531311\n",
      "\n",
      "validation phase, current loss is 0.595323830940259\n",
      "validation phase, current accuracy is 0.6697497367858887\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 4 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.5821298356284239\n",
      "training phase, current accuracy is 0.6844809651374817\n",
      "\n",
      "validation phase, current loss is 0.6074254661960623\n",
      "validation phase, current accuracy is 0.6354733109474182\n",
      "\n",
      "Epoch 5 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.571057404841054\n",
      "training phase, current accuracy is 0.6943957209587097\n",
      "\n",
      "validation phase, current loss is 0.5688562091598054\n",
      "validation phase, current accuracy is 0.6898803114891052\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 6 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.5680720696937331\n",
      "training phase, current accuracy is 0.6960280537605286\n",
      "\n",
      "validation phase, current loss is 0.5935323261073158\n",
      "validation phase, current accuracy is 0.6577801704406738\n",
      "\n",
      "Epoch 7 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.5575777636236798\n",
      "training phase, current accuracy is 0.7081796526908875\n",
      "\n",
      "validation phase, current loss is 0.5695491704250705\n",
      "validation phase, current accuracy is 0.6822633147239685\n",
      "\n",
      "Epoch 8 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.5483949774788741\n",
      "training phase, current accuracy is 0.717973530292511\n",
      "\n",
      "validation phase, current loss is 0.5571918194389965\n",
      "validation phase, current accuracy is 0.6980413198471069\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 9 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.5468246320752508\n",
      "training phase, current accuracy is 0.7191221714019775\n",
      "\n",
      "validation phase, current loss is 0.5556182184208983\n",
      "validation phase, current accuracy is 0.6969531774520874\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 10 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.5305100245362189\n",
      "training phase, current accuracy is 0.7359893918037415\n",
      "\n",
      "validation phase, current loss is 0.557220496148098\n",
      "validation phase, current accuracy is 0.6936887502670288\n",
      "\n",
      "Epoch 11 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.5227362906588341\n",
      "training phase, current accuracy is 0.7408258318901062\n",
      "\n",
      "validation phase, current loss is 0.5677735375501904\n",
      "validation phase, current accuracy is 0.6969531774520874\n",
      "\n",
      "Epoch 12 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.5133038674586557\n",
      "training phase, current accuracy is 0.7518892288208008\n",
      "\n",
      "validation phase, current loss is 0.5608703771016283\n",
      "validation phase, current accuracy is 0.6991294622421265\n",
      "\n",
      "Epoch 13 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.4991666864263457\n",
      "training phase, current accuracy is 0.7693609595298767\n",
      "\n",
      "validation phase, current loss is 0.5458338856697083\n",
      "validation phase, current accuracy is 0.7067464590072632\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 14 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.49071018590862836\n",
      "training phase, current accuracy is 0.7749229073524475\n",
      "\n",
      "validation phase, current loss is 0.5676770327659374\n",
      "validation phase, current accuracy is 0.6730141043663025\n",
      "\n",
      "Epoch 15 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.48227613031608324\n",
      "training phase, current accuracy is 0.7769179940223694\n",
      "\n",
      "validation phase, current loss is 0.5453872205578074\n",
      "validation phase, current accuracy is 0.7121871113777161\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 16 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.46144524399526937\n",
      "training phase, current accuracy is 0.8088991045951843\n",
      "\n",
      "validation phase, current loss is 0.5501073601780311\n",
      "validation phase, current accuracy is 0.6936887502670288\n",
      "\n",
      "Epoch 17 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.45041893908258407\n",
      "training phase, current accuracy is 0.812103271484375\n",
      "\n",
      "validation phase, current loss is 0.5366473037413078\n",
      "validation phase, current accuracy is 0.7110990285873413\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 18 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.4378376087941467\n",
      "training phase, current accuracy is 0.8275799751281738\n",
      "\n",
      "validation phase, current loss is 0.5386079701557512\n",
      "validation phase, current accuracy is 0.6996735334396362\n",
      "\n",
      "Epoch 19 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.42290676466917504\n",
      "training phase, current accuracy is 0.8374947309494019\n",
      "\n",
      "validation phase, current loss is 0.5503697641137116\n",
      "validation phase, current accuracy is 0.7051142454147339\n",
      "\n",
      "Epoch 20 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.4091822545427948\n",
      "training phase, current accuracy is 0.8471676707267761\n",
      "\n",
      "validation phase, current loss is 0.5404221914927511\n",
      "validation phase, current accuracy is 0.7132752537727356\n",
      "\n",
      "Epoch 21 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.3946335745775947\n",
      "training phase, current accuracy is 0.8621606826782227\n",
      "\n",
      "validation phase, current loss is 0.5342324709477181\n",
      "validation phase, current accuracy is 0.7149074673652649\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 22 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.3777257804426372\n",
      "training phase, current accuracy is 0.8751587271690369\n",
      "\n",
      "validation phase, current loss is 0.536530363871042\n",
      "validation phase, current accuracy is 0.7149074673652649\n",
      "\n",
      "Epoch 23 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.3659957535112216\n",
      "training phase, current accuracy is 0.8845293521881104\n",
      "\n",
      "validation phase, current loss is 0.5426181639109914\n",
      "validation phase, current accuracy is 0.7062023878097534\n",
      "\n",
      "Epoch 24 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.3527102290693963\n",
      "training phase, current accuracy is 0.8948673009872437\n",
      "\n",
      "validation phase, current loss is 0.5345514795466269\n",
      "validation phase, current accuracy is 0.7116430997848511\n",
      "\n",
      "Epoch 25 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.3346775297252755\n",
      "training phase, current accuracy is 0.9142736196517944\n",
      "\n",
      "validation phase, current loss is 0.5328904292399268\n",
      "validation phase, current accuracy is 0.7062023878097534\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 26 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.32076857915150053\n",
      "training phase, current accuracy is 0.9238256216049194\n",
      "\n",
      "validation phase, current loss is 0.5432276287976494\n",
      "validation phase, current accuracy is 0.7067464590072632\n",
      "\n",
      "Epoch 27 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.3094139997478869\n",
      "training phase, current accuracy is 0.9298712611198425\n",
      "\n",
      "validation phase, current loss is 0.5417912955577278\n",
      "validation phase, current accuracy is 0.7007616758346558\n",
      "\n",
      "Epoch 28 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.2994265118660571\n",
      "training phase, current accuracy is 0.9368841052055359\n",
      "\n",
      "validation phase, current loss is 0.5347701940235557\n",
      "validation phase, current accuracy is 0.7105549573898315\n",
      "\n",
      "Epoch 29 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.29022417933633443\n",
      "training phase, current accuracy is 0.9407532811164856\n",
      "\n",
      "validation phase, current loss is 0.5666714592130452\n",
      "validation phase, current accuracy is 0.6855277419090271\n",
      "\n",
      "Epoch 30 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.27622176213568883\n",
      "training phase, current accuracy is 0.9558672308921814\n",
      "\n",
      "validation phase, current loss is 0.5349386751457189\n",
      "validation phase, current accuracy is 0.7132752537727356\n",
      "\n",
      "Epoch 31 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.2694548200911633\n",
      "training phase, current accuracy is 0.953751266002655\n",
      "\n",
      "validation phase, current loss is 0.543887558258397\n",
      "validation phase, current accuracy is 0.707290530204773\n",
      "\n",
      "Epoch 32 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.26161336217751907\n",
      "training phase, current accuracy is 0.9568949937820435\n",
      "\n",
      "validation phase, current loss is 0.5487521361798794\n",
      "validation phase, current accuracy is 0.7083786725997925\n",
      "\n",
      "Epoch 33 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.2507543698386539\n",
      "training phase, current accuracy is 0.9674143195152283\n",
      "\n",
      "validation phase, current loss is 0.5463108305573074\n",
      "validation phase, current accuracy is 0.7023938894271851\n",
      "\n",
      "Epoch 34 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.24511738790219542\n",
      "training phase, current accuracy is 0.9680188894271851\n",
      "\n",
      "validation phase, current loss is 0.5434671014514919\n",
      "validation phase, current accuracy is 0.7078346014022827\n",
      "\n",
      "Epoch 35 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.23691337342367777\n",
      "training phase, current accuracy is 0.9733389616012573\n",
      "\n",
      "validation phase, current loss is 0.544790305951215\n",
      "validation phase, current accuracy is 0.7089227437973022\n",
      "\n",
      "Epoch 36 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.23086174165104933\n",
      "training phase, current accuracy is 0.9761199355125427\n",
      "\n",
      "validation phase, current loss is 0.5583018084604929\n",
      "validation phase, current accuracy is 0.7051142454147339\n",
      "\n",
      "Epoch 37 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.22760795335636758\n",
      "training phase, current accuracy is 0.9759385585784912\n",
      "\n",
      "validation phase, current loss is 0.5507755888559095\n",
      "validation phase, current accuracy is 0.6996735334396362\n",
      "\n",
      "Epoch 38 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.22157623399526274\n",
      "training phase, current accuracy is 0.9800495505332947\n",
      "\n",
      "validation phase, current loss is 0.5516783424508196\n",
      "validation phase, current accuracy is 0.7034820318222046\n",
      "\n",
      "Epoch 39 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.21769876472283056\n",
      "training phase, current accuracy is 0.9787800312042236\n",
      "\n",
      "validation phase, current loss is 0.5483019687924473\n",
      "validation phase, current accuracy is 0.7078346014022827\n",
      "\n",
      "Epoch 40 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.21772477036789867\n",
      "training phase, current accuracy is 0.9773895144462585\n",
      "\n",
      "validation phase, current loss is 0.5523527574617014\n",
      "validation phase, current accuracy is 0.7078346014022827\n",
      "\n",
      "Epoch 41 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.2070146438877785\n",
      "training phase, current accuracy is 0.9830723404884338\n",
      "\n",
      "validation phase, current loss is 0.5576092755184858\n",
      "validation phase, current accuracy is 0.7078346014022827\n",
      "\n",
      "Epoch 42 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.20597482801968325\n",
      "training phase, current accuracy is 0.9831932783126831\n",
      "\n",
      "validation phase, current loss is 0.5510696495059265\n",
      "validation phase, current accuracy is 0.7013057470321655\n",
      "\n",
      "Epoch 43 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.20394324068470795\n",
      "training phase, current accuracy is 0.9842210412025452\n",
      "\n",
      "validation phase, current loss is 0.5708221061574751\n",
      "validation phase, current accuracy is 0.6996735334396362\n",
      "\n",
      "Epoch 44 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.2000392313991894\n",
      "training phase, current accuracy is 0.9844628572463989\n",
      "\n",
      "validation phase, current loss is 0.5539405645561426\n",
      "validation phase, current accuracy is 0.7045701742172241\n",
      "\n",
      "Epoch 45 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.1977617099091116\n",
      "training phase, current accuracy is 0.9868810772895813\n",
      "\n",
      "validation phase, current loss is 0.5512714673307957\n",
      "validation phase, current accuracy is 0.7105549573898315\n",
      "\n",
      "Epoch 46 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.1959773344328683\n",
      "training phase, current accuracy is 0.9869415163993835\n",
      "\n",
      "validation phase, current loss is 0.554606770600017\n",
      "validation phase, current accuracy is 0.7105549573898315\n",
      "\n",
      "Epoch 47 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.19289351748779474\n",
      "training phase, current accuracy is 0.9868810772895813\n",
      "\n",
      "validation phase, current loss is 0.5859339954544333\n",
      "validation phase, current accuracy is 0.693144679069519\n",
      "\n",
      "Epoch 48 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.1901954221702762\n",
      "training phase, current accuracy is 0.9882110953330994\n",
      "\n",
      "validation phase, current loss is 0.5500747200194848\n",
      "validation phase, current accuracy is 0.7067464590072632\n",
      "\n",
      "Epoch 49 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.1878603206618969\n",
      "training phase, current accuracy is 0.9893597960472107\n",
      "\n",
      "validation phase, current loss is 0.5647518380552173\n",
      "validation phase, current accuracy is 0.7023938894271851\n",
      "\n",
      "Epoch 50 of 50\n",
      "--------------------\n",
      "training phase, current loss is 0.1873054260035667\n",
      "training phase, current accuracy is 0.989722490310669\n",
      "\n",
      "validation phase, current loss is 0.5521975254337987\n",
      "validation phase, current accuracy is 0.6996735334396362\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T14:53:22.165811Z",
     "start_time": "2025-03-22T14:52:43.492371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HFCNN(1024)\n",
    "model.load_state_dict(torch.load('bestloss_CNN_model_1024out_00075WD.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "preds = []\n",
    "targets = []\n",
    "for i, (input, target) in enumerate(test_loader):\n",
    "    input = input.to(device)\n",
    "    targets += target.tolist()\n",
    "    output = model(input)\n",
    "    preds += (F.sigmoid(output) > 0.5).float().tolist()\n",
    "\n",
    "acc = accuracy_score(targets, preds)\n",
    "prec = precision_score(targets, preds)\n",
    "rec = recall_score(targets, preds)\n",
    "f1 = f1_score(targets, preds)\n",
    "\n",
    "print('Test Accuracy is {:.4f}'.format(acc))\n",
    "print('Test Precision is {:.4f}'.format(prec))\n",
    "print('Test Recall is {:.4f}'.format(rec))\n",
    "print('Test F1 score is {:.4f}'.format(f1))"
   ],
   "id": "dc4d74ed8ea28961",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is 0.7499\n",
      "Test Precision is 0.7512\n",
      "Test Recall is 0.7519\n",
      "Test F1 score is 0.7516\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 30 day readmission case",
   "id": "8e268421416dad42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:35:13.815909Z",
     "start_time": "2025-03-24T00:35:09.284654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectors_all_30Re, labels_30Re, neg_idx_sample = generate_dataset(df_data_30Re, pos_30Re_idx, neg_30Re_idx, '30_RE')\n",
    "x_train, x_test, y_train, y_test = train_test_split(vectors_all_30Re, labels_30Re, test_size=0.1, shuffle=True)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, shuffle=True)\n",
    "\n",
    "num_neg = len(x_train) // 2\n",
    "neg_idx_unsampled = [i for i in neg_30Re_idx if i not in neg_idx_sample]\n",
    "add_neg_idx = np.random.choice(neg_idx_sample, size=num_neg, replace=False).tolist()\n",
    "add_x_neg = df_data.iloc[add_neg_idx, :]['TOKENS'].tolist()\n",
    "add_x_neg = [vectorize(itm) for itm in add_x_neg]\n",
    "add_y_neg = df_data.iloc[add_neg_idx, :]['30_RE'].tolist()\n",
    "x_train = x_train + add_x_neg\n",
    "y_train = y_train + add_y_neg\n",
    "add_pos_idx = np.where(np.array(y_train) == 1)[0]\n",
    "add_x_pos = [x_train[i] for i in add_pos_idx]\n",
    "add_y_pos = [y_train[i] for i in add_pos_idx]\n",
    "x_train = x_train + add_x_pos\n",
    "y_train = y_train + add_y_pos\n",
    "\n",
    "dataset_train = HFDataset(x_train, y_train)\n",
    "dataset_val = HFDataset(x_val, y_val)\n",
    "dataset_test = HFDataset(x_test, y_test)\n",
    "print('{:.1f}% of training set are positive examples'.format(np.sum(y_train) / len(y_train) * 100))\n",
    "print('{:.1f}% of validation set are positive examples'.format(np.sum(y_val) / len(y_val) * 100))\n",
    "print('{:.1f}% of test set are positive examples'.format(np.sum(y_test) / len(y_test) * 100))"
   ],
   "id": "c2aa80bfd1320c07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.9% of training set are positive examples\n",
      "49.4% of validation set are positive examples\n",
      "51.8% of test set are positive examples\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:35:17.171856Z",
     "start_time": "2025-03-24T00:35:17.160464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(dataset=dataset_train, batch_size=128, shuffle=True, collate_fn=collate_data)\n",
    "val_loader = DataLoader(dataset=dataset_val, batch_size=128, shuffle=True, collate_fn=collate_data)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=128, shuffle=True, collate_fn=collate_data)"
   ],
   "id": "4f8836993f352b9b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:42:16.596597Z",
     "start_time": "2025-03-24T00:40:17.035581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HFCNN(1024).to(device)\n",
    "model.load_state_dict(torch.load('bestloss_CNN_model_30Re.pth'))\n",
    "num_epoch = 5\n",
    "sizes = {'training': len(x_train), 'validation': len(x_val)}\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.02)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_val_loss = np.inf\n",
    "# best_val_acc = 0.\n",
    "train_loss_ls = []\n",
    "val_loss_ls = []\n",
    "train_acc_ls = []\n",
    "val_acc_ls = []\n",
    "for epoch in range(num_epoch):\n",
    "    print('Epoch {} of {}'.format(epoch+1, num_epoch))\n",
    "    print('-' * 20)\n",
    "    for phase in ['training', 'validation']:\n",
    "        if phase == 'training':\n",
    "            model.train()\n",
    "            dataloader = train_loader\n",
    "        else:\n",
    "            model.eval()\n",
    "            dataloader = val_loader\n",
    "        epoch_loss = 0.\n",
    "        epoch_correct = 0.\n",
    "        for i, (input, target) in enumerate(dataloader):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase == 'training'):\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target)\n",
    "                if phase == 'training':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            epoch_loss += loss.item() * input.shape[0]\n",
    "            preds = (F.sigmoid(output) > 0.5).float()\n",
    "            epoch_correct += torch.sum(preds == target.data)\n",
    "\n",
    "        epoch_loss = epoch_loss / sizes[phase]\n",
    "        epoch_acc = (epoch_correct / sizes[phase]).item()\n",
    "        \n",
    "        if phase == 'training':\n",
    "            train_loss_ls.append(epoch_loss)\n",
    "            train_acc_ls.append(epoch_acc)\n",
    "        else:\n",
    "            val_loss_ls.append(epoch_loss)\n",
    "            val_acc_ls.append(epoch_acc)\n",
    "        \n",
    "        # if phase == 'validation' and epoch_acc > best_val_acc:\n",
    "        #     best_val_acc = epoch_acc\n",
    "        #     torch.save(model.state_dict(), 'best_CNN_model.pth')\n",
    "        \n",
    "        print('{} phase, current loss is {}'.format(phase, epoch_loss))\n",
    "        print('{} phase, current accuracy is {}'.format(phase, epoch_acc))\n",
    "        print()\n",
    "        \n",
    "        if phase == 'validation' and epoch_loss < best_val_loss:\n",
    "            best_val_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), 'best_CNN_model.pth')\n",
    "            print('Best model saved')\n",
    "            print()\n",
    "\n",
    "training_curves = {'train loss': train_loss_ls, 'train accuracy': train_acc_ls, 'val loss': val_loss_ls, 'val accuracy': val_acc_ls}\n",
    "training_curves = pd.DataFrame(training_curves)\n",
    "training_curves.to_csv('training_curves.csv', index=False)"
   ],
   "id": "58eb4ec4927d8b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 5\n",
      "--------------------\n",
      "training phase, current loss is 0.588215542011812\n",
      "training phase, current accuracy is 0.6815409660339355\n",
      "\n",
      "validation phase, current loss is 0.6053535307960949\n",
      "validation phase, current accuracy is 0.6954023241996765\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 2 of 5\n",
      "--------------------\n",
      "training phase, current loss is 0.54387531691914\n",
      "training phase, current accuracy is 0.7229534983634949\n",
      "\n",
      "validation phase, current loss is 0.6020084441393271\n",
      "validation phase, current accuracy is 0.6954023241996765\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 3 of 5\n",
      "--------------------\n",
      "training phase, current loss is 0.5123018997056143\n",
      "training phase, current accuracy is 0.7537720799446106\n",
      "\n",
      "validation phase, current loss is 0.5957336603910074\n",
      "validation phase, current accuracy is 0.7183908224105835\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 4 of 5\n",
      "--------------------\n",
      "training phase, current loss is 0.4874409340836263\n",
      "training phase, current accuracy is 0.7833065986633301\n",
      "\n",
      "validation phase, current loss is 0.5932833237209539\n",
      "validation phase, current accuracy is 0.7126436829566956\n",
      "\n",
      "Best model saved\n",
      "\n",
      "Epoch 5 of 5\n",
      "--------------------\n",
      "training phase, current loss is 0.4661737944876975\n",
      "training phase, current accuracy is 0.8083467483520508\n",
      "\n",
      "validation phase, current loss is 0.5922273972938801\n",
      "validation phase, current accuracy is 0.7471264600753784\n",
      "\n",
      "Best model saved\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:42:19.211017Z",
     "start_time": "2025-03-24T00:42:18.451359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HFCNN(1024)\n",
    "model.load_state_dict(torch.load('best_CNN_model.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "preds = []\n",
    "targets = []\n",
    "for i, (input, target) in enumerate(test_loader):\n",
    "    input = input.to(device)\n",
    "    targets += target.tolist()\n",
    "    output = model(input)\n",
    "    preds += (F.sigmoid(output) > 0.5).float().tolist()\n",
    "\n",
    "acc = accuracy_score(targets, preds)\n",
    "prec = precision_score(targets, preds)\n",
    "rec = recall_score(targets, preds)\n",
    "f1 = f1_score(targets, preds)\n",
    "\n",
    "print('Test Accuracy is {:.4f}'.format(acc))\n",
    "print('Test Precision is {:.4f}'.format(prec))\n",
    "print('Test Recall is {:.4f}'.format(rec))\n",
    "print('Test F1 score is {:.4f}'.format(f1))"
   ],
   "id": "394529f168333160",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is 0.7047\n",
      "Test Precision is 0.6937\n",
      "Test Recall is 0.7700\n",
      "Test F1 score is 0.7299\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e854da81f24d160"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
